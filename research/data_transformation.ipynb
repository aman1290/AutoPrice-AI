{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497d0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae23b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\anand\\\\Desktop\\\\reume_projet\\\\AutoPrice-AI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1d04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d14692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\anand\\\\Desktop\\\\reume_projet\\\\AutoPrice-AI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9b308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d03db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd7392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7f185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93032faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd44b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_test_splitting(self):\n",
    "        \"\"\"Complete data transformation and splitting pipeline\"\"\"\n",
    "        try:\n",
    "            # 1. Load data\n",
    "            data = pd.read_csv(self.config.data_path)\n",
    "            logger.info(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "            # 2. Convert numeric columns\n",
    "            numeric_cols = ['km_driven', 'engine', 'price', 'reg_year_int']\n",
    "            for col in numeric_cols:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "            # 3. Handle null values\n",
    "            logger.info(\"Handling null values\")\n",
    "            null_counts = data.isnull().sum()\n",
    "            logger.info(f\"Null values detected:\\n{null_counts[null_counts > 0]}\")\n",
    "            \n",
    "            data = data.dropna(subset=['price'])\n",
    "            data['engine'] = data['engine'].fillna(data['engine'].mode()[0])\n",
    "            data['km_driven'] = data['km_driven'].fillna(data['km_driven'].median())\n",
    "            data['transmission'] = data['transmission'].fillna(data['transmission'].mode()[0])\n",
    "            data['ownership'] = data['ownership'].fillna('Unknown')\n",
    "\n",
    "            # 4. Clean data\n",
    "            logger.info(\"Cleaning data\")\n",
    "            data['ownership'] = data['ownership'].map({\n",
    "                'First Owner': 1, 'Second Owner': 2, 'Third Owner': 3,\n",
    "                'Fourth Owner': 4, 'Fifth Owner': 5, 'Unknown': -1\n",
    "            })\n",
    "            \n",
    "            model_split = data['model'].str.split(n=1, expand=True)\n",
    "            data['model_base'] = model_split[0]\n",
    "            data['variant'] = model_split[1].fillna('Standard')\n",
    "            data['is_automatic'] = (data['transmission'] == 'Automatic').astype(int)\n",
    "\n",
    "            # 5. Add features\n",
    "            logger.info(\"Adding features\")\n",
    "            data['price_per_cc'] = data['price'] / data['engine']\n",
    "            data['car_age'] = pd.Timestamp.now().year - data['reg_year_int']\n",
    "            data['km_per_year'] = data['km_driven'] / data['car_age']\n",
    "            data['age_group'] = pd.cut(\n",
    "                data['car_age'],\n",
    "                bins=[0, 3, 7, 12, float('inf')],\n",
    "                labels=['New', 'Mid', 'Old', 'Vintage']\n",
    "            )\n",
    "\n",
    "            # 6. Split data\n",
    "            train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "            \n",
    "            # 7. Save results\n",
    "            os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "            train_path = os.path.join(self.config.root_dir, \"train.csv\")\n",
    "            test_path = os.path.join(self.config.root_dir, \"test.csv\")\n",
    "            train.to_csv(train_path, index=False)\n",
    "            test.to_csv(test_path, index=False)\n",
    "            \n",
    "            logger.info(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "            return train_path, test_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data transformation failed: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48e7667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-15 03:22:51,934: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-15 03:22:51,937: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-15 03:22:51,940: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-06-15 03:22:51,942: INFO: common: created directory at: artifacts]\n",
      "[2025-06-15 03:22:51,944: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-06-15 03:22:51,956: INFO: 2567506077: Original data shape: (2294, 11)]\n",
      "[2025-06-15 03:22:51,958: INFO: 2567506077: Handling null values]\n",
      "[2025-06-15 03:22:51,961: INFO: 2567506077: Null values detected:\n",
      "km_driven       17\n",
      "reg_year_int    12\n",
      "car_age         12\n",
      "price            2\n",
      "dtype: int64]\n",
      "[2025-06-15 03:22:51,968: INFO: 2567506077: Cleaning data]\n",
      "[2025-06-15 03:22:51,975: INFO: 2567506077: Adding features]\n",
      "[2025-06-15 03:22:52,016: INFO: 2567506077: Train shape: (1719, 17), Test shape: (573, 17)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        config = ConfigurationManager()\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(config=data_transformation_config)\n",
    "        train_path, test_path = data_transformation.train_test_splitting()  # Note the corrected method name\n",
    "except Exception as e:\n",
    "        logger.exception(\"Pipeline failed\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027ce13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
